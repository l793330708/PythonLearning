{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as NN\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "src_path = \"E:\\\\MLiA_SourceCode\\\\machinelearninginaction\\\\Ch02\\\\\"\n",
    "# trainLen = len(os.listdir(src_path+\"trainingDigits\"))\n",
    "# fr = open(src_path+\"trainingDigits\\\\0_0.txt\")\n",
    "# for line in fr.readlines():\n",
    "#     print(len(line))\n",
    "#     break\n",
    "# TestLen = len(os.listdir(src_path+\"testDigits\"))\n",
    "class myCNN(NN.Module):\n",
    "    def __init__(self):\n",
    "        super(myCNN,self).__init__()\n",
    "        self.conv1 = NN.Conv2d(1,16,5)\n",
    "        self.conv2 = NN.Conv2d(16,32,5)\n",
    "        self.pool = NN.MaxPool2d(2,2)\n",
    "        self.fc1 = NN.Linear(32*5*5,100)\n",
    "        self.fc2 = NN.Linear(100,10)\n",
    "        self.softmax = NN.Softmax(dim=1)\n",
    "        self.activation = NN.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x) ## 16*28*28\n",
    "        x = self.pool(x) ## 16*14*14\n",
    "        x = self.conv2(x) ## 32*10*10\n",
    "        x = self.pool(x) ## 32*5*5\n",
    "        x = x.view(-1, 32*5*5) ##flatten\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "train_label = []\n",
    "train_labels = []\n",
    "one_hot_tmp= np.zeros((1,10),dtype=np.int16)\n",
    "for labelArr in (os.listdir(src_path+\"trainingDigits\")):\n",
    "    trueLabel = int(labelArr.strip().split(\"_\")[0])\n",
    "    train_labels.append(trueLabel)\n",
    "    one_hot_tmp[0][trueLabel] = 1\n",
    "    train_label.append(one_hot_tmp.tolist())\n",
    "#     one_hot_tmp[trueLabel] = 0\n",
    "    one_hot_tmp= np.zeros((1,10),dtype=np.int16)\n",
    "net = myCNN()\n",
    "# print(train_label)\n",
    "def getDataMatrix(path):\n",
    "    flist = os.listdir(path)\n",
    "    DataMatrix = []\n",
    "    for i in flist:\n",
    "        tmpMat = np.zeros((32,32))\n",
    "        fr = open(path+'\\\\'+i)\n",
    "        tmp = np.zeros((32,32),dtype=np.int16)\n",
    "        lines = fr.readlines()\n",
    "        length =len(lines)\n",
    "        for j in range(length):\n",
    "             for k in range(len(lines[j])-1):\n",
    "                 tmpMat[j,k]= lines[j][k]\n",
    "            \n",
    "        DataMatrix.append(tmpMat.tolist())\n",
    "    return DataMatrix\n",
    "        \n",
    "trainMat = getDataMatrix(src_path+\"trainingDigits\")\n",
    "trainMat = torch.tensor(trainMat,dtype=torch.float32).unsqueeze(1)\n",
    "train_labels = torch.tensor(train_labels,dtype=torch.long)\n",
    "train_label = torch.tensor(train_label,dtype=torch.float32).squeeze(1)\n",
    "print(trainMat.size(),train_label.size(),train_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = torch.rand(1,1,32,32)\n",
    "# print(x1)\n",
    "import torch.optim as optim\n",
    "loss_fn = NN.MSELoss()\n",
    "optimizier = optim.SGD(net.parameters(),lr=1e-4)\n",
    "# optimizier = optim.Adam(net.parameters(),lr = 1e-6)\n",
    "\n",
    "# miniBatchSize = 20\n",
    "# round = int(500/miniBatchSize) \n",
    "for i in range(500):\n",
    "#     out = net(trainMat[i*miniBatchSize:i*miniBatchSize+19,:])\n",
    "#     loss = loss_fn(out, train_label[i*miniBatchSize:i*miniBatchSize+19])\n",
    "    out = net(trainMat)\n",
    "    loss = loss_fn(out, train_label)\n",
    "    optimizier.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizier.step()\n",
    "# print(out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 189, 1: 1, 3: 1, 4: 2, 6: 2, 9: 1}\n",
      "196 0.10134436401240951\n"
     ]
    }
   ],
   "source": [
    "ec = 0\n",
    "Error_dic = {}\n",
    "Error_index = []\n",
    "for i in range(len(train_labels)):\n",
    "    if torch.argmax(out[i],dim=0).item()!=train_labels[i]:\n",
    "        ec = ec + 1\n",
    "        Error_index.append(i)\n",
    "        Error_dic[train_labels[i].item()] = Error_dic.get(train_labels[i].item(),0)+1\n",
    "# print(torch.argmax(out[i],dim=0).item(),train_labels[i])\n",
    "print(Error_dic)\n",
    "print(ec, ec/len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = './minstCnnByMyOwn_net.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "net = myCNN()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 87, 1: 1, 2: 2, 3: 6, 4: 1, 5: 3, 6: 1, 7: 2, 8: 1, 9: 2} 0.11205073995771671\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "testMat = getDataMatrix(src_path+\"testDigits\")\n",
    "testMat = torch.tensor(testMat,dtype=torch.float32).unsqueeze(1)\n",
    "test_label = []\n",
    "for labelArr in (os.listdir(src_path+\"testDigits\")):\n",
    "    trueLabel = int(labelArr.strip().split(\"_\")[0])\n",
    "    test_label.append(trueLabel)\n",
    "out = net(testMat)\n",
    "test_error_dict={} \n",
    "ec_test = 0\n",
    "for i in range(len(test_label)):\n",
    "#     print(torch.argmax(out[i].item(),dim=0), test_label[i])\n",
    "    if (torch.argmax(out[i],dim=0).item())!= test_label[i]:\n",
    "        test_error_dict[test_label[i]] = test_error_dict.get(test_label[i], 0)+1\n",
    "        ec_test = ec_test +1\n",
    "\n",
    "print(test_error_dict,ec_test/len(test_label))\n",
    "# print(“error rate is {}”.format{test_error_dict.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
